---
layout: post
title:  Critical Doing: SIFT for AI 
description: A new method focusing on a SIFT-like framework of “moves” around AI and improving AI input through well-crafted, evidence-based follow up questions 

date:   2025-11-13
image:  '/images/tore-f-iEkIBYpsBog-unsplash.jpg'
tags:   [SIFT, AI]
featured: true
---
> ...the core question of personal fact-checking as “Is this what people think it is?” There’s actually some deep epistemological insights under that shift, but the simplest way to conceptualize it is being misinformed (either by yourself or others) is not about the relation between something you are looking at and the truth. Being misinformed is usually about bad evidence. The most common pattern is this: without context something looks like good evidence of something. Once you have the context of that evidence it does not.
>
> <cite>Mike Caulfield</cite>

Mike Caulfield’s prototype method was developed over the last three years to address the fact that we focus too much on “critical thinking” with AI without really knowing what that means or how it should be defined. Instead, this new method of “critical doing” focuses on a SIFT-like framework of “moves” around AI and improving AI input through well-crafted, evidence-based follow up questions. 

<a href="{{site.baseurl}}/files/Critical Doing_ SIFT for AI-1.pdf" class="button" target="_blank">In Development: SIFT for AI Workshop</a>


Caulfield has an entire channel dedicated to SIFT for AI on YouTube: 
<p><iframe src="https://www.youtube.com/watch?v=xBbP_DophvE" frameborder="0" allowfullscreen></iframe></p>

